import pandas as pd
import numpy as np
import json
import os
import time
from datetime import datetime
import random
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, 
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler("stock_data_baostock.log"), logging.StreamHandler()])
logger = logging.getLogger('stock_data_baostock_fetcher')

# æ£€æŸ¥baostockå¯ç”¨æ€§
try:
    import baostock as bs
    BAOSTOCK_AVAILABLE = True
except ImportError:
    BAOSTOCK_AVAILABLE = False
    logger.warning("âš ï¸  baostockåº“æœªå®‰è£…ï¼Œè¿è¡Œ `pip install baostock` ä»¥å¯ç”¨baostockæ•°æ®æº")

# ç¡®ä¿cacheç›®å½•å­˜åœ¨
if not os.path.exists('cache'):
    os.makedirs('cache')

# åçˆ¬é…ç½®
class AntiCrawlConfig:
    # è¯·æ±‚å»¶è¿Ÿé…ç½® (ç§’)
    MIN_DELAY = 0.5  # æœ€å°å»¶è¿Ÿ
    MAX_DELAY = 2.0  # æœ€å¤§å»¶è¿Ÿ
    
    # æ‰¹æ¬¡å¤„ç†å»¶è¿Ÿé…ç½® (ç§’)
    BATCH_MIN_DELAY = 3.0  # æ‰¹æ¬¡é—´æœ€å°å»¶è¿Ÿ
    BATCH_MAX_DELAY = 5.0  # æ‰¹æ¬¡é—´æœ€å¤§å»¶è¿Ÿ
    
    # å•åªè‚¡ç¥¨å¤„ç†é—´éš” (ç§’)
    STOCK_MIN_INTERVAL = 0.5  # è‚¡ç¥¨é—´æœ€å°é—´éš”
    
    # é‡è¯•é…ç½®
    MAX_RETRIES = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°

# åˆ›å»ºåçˆ¬é…ç½®å®ä¾‹
ANTI_CRAWL_CONFIG = AntiCrawlConfig()

# æ·»åŠ éšæœºå»¶è¿Ÿ
def add_random_delay(min_delay=None, max_delay=None):
    min_delay = min_delay or AntiCrawlConfig.MIN_DELAY
    max_delay = max_delay or AntiCrawlConfig.MAX_DELAY
    delay = random.uniform(min_delay, max_delay)
    time.sleep(delay)

# æ•°æ®è®¿é—®æ§åˆ¶ç±»
class RateLimiter:
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(RateLimiter, cls).__new__(cls)
            cls._instance.reset()
        return cls._instance
    
    def reset(self):
        self.request_counts = {
            'baostock': 0
        }
        self.last_reset_times = {
            'baostock': time.time()
        }
        self.rate_limits = {
            'baostock': 100  # æ¯åˆ†é’Ÿæœ€å¤šè¯·æ±‚æ•°
        }
    
    def check_rate_limit(self, source):
        current_time = time.time()
        elapsed = current_time - self.last_reset_times[source]
        
        # æ¯åˆ†é’Ÿé‡ç½®è®¡æ•°
        if elapsed >= 60:
            self.request_counts[source] = 0
            self.last_reset_times[source] = current_time
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        if self.request_counts[source] >= self.rate_limits[source]:
            wait_time = 60 - elapsed + 1  # ç­‰å¾…åˆ°ä¸‹ä¸€åˆ†é’Ÿå†ç»§ç»­
            logger.warning(f"[{source}] å·²è¾¾è¯·æ±‚é™åˆ¶ï¼Œç­‰å¾… {wait_time:.1f} ç§’")
            time.sleep(wait_time)
            self.request_counts[source] = 0
            self.last_reset_times[source] = time.time()
        
        # å¢åŠ è®¡æ•°
        self.request_counts[source] += 1

# åˆå§‹åŒ–è®¿é—®æ§åˆ¶å™¨
rate_limiter = RateLimiter()

def get_stock_list():
    """ä»æœ¬åœ°æ–‡ä»¶è¯»å–è‚¡ç¥¨åˆ—è¡¨"""
    try:
        stock_list = pd.read_csv('cache/stockA_list.csv')
        print(f"âœ… æˆåŠŸè¯»å–è‚¡ç¥¨åˆ—è¡¨ï¼Œå…±{len(stock_list)}åªè‚¡ç¥¨")
        return stock_list
    except Exception as e:
        print(f"âŒ è¯»å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        return None

def load_progress():
    """åŠ è½½è¿›åº¦ä¿¡æ¯"""
    progress_file = 'cache/fundamentals_baostock_progress.json'
    if os.path.exists(progress_file):
        try:
            with open(progress_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return {"last_index": 0, "completed_codes": []}

def save_progress(index, completed_codes):
    """ä¿å­˜è¿›åº¦ä¿¡æ¯"""
    progress_file = 'cache/fundamentals_baostock_progress.json'
    try:
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump({"last_index": index, "completed_codes": completed_codes}, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸  ä¿å­˜è¿›åº¦å¤±è´¥: {e}")

def get_fundamentals_from_baostock(code):
    """ä½¿ç”¨baostockè·å–å®Œæ•´çš„åŸºæœ¬é¢æ•°æ®ï¼ŒåŒ…å«è®¿é—®æ§åˆ¶ç­–ç•¥"""
    if not BAOSTOCK_AVAILABLE:
        logger.warning("âš ï¸  baostockåº“æœªå®‰è£…ï¼Œæ— æ³•è·å–æ•°æ®")
        return None
        
    try:
        # æ£€æŸ¥è®¿é—®é¢‘ç‡é™åˆ¶
        rate_limiter.check_rate_limit('baostock')
        
        # ç™»å½•baostock
        lg = bs.login()
        if lg.error_code != '0':
            logger.error(f"âŒ baostockç™»å½•å¤±è´¥: {lg.error_msg}")
            return None
        
        # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé˜²æ­¢è¯·æ±‚è¿‡å¿«
        add_random_delay()
        
        # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼ï¼ˆ000001 -> sz.000001ï¼‰
        market_code = f"sz.{code}" if str(code).startswith(('0', '3')) else f"sh.{code}"
        
        # åˆå§‹åŒ–åŸºæœ¬é¢æ•°æ®å­—å…¸
        fundamental = {
            'è‚¡ç¥¨ä»£ç ': code,
            'è‚¡ç¥¨åç§°': '',
            'è‚¡ç¥¨ä¸Šå¸‚æ—¥æœŸ': '',
            'è‚¡ç¥¨ä¸Šå¸‚åœ°ç‚¹': 'ä¸Šæµ·' if str(code).startswith(('6', '5')) else 'æ·±åœ³',
            'è‚¡ç¥¨æ‰€å±è¡Œä¸š': '',
            
            # ç›ˆåˆ©èƒ½åŠ›
            'æ¯è‚¡æ”¶ç›Š': '',
            'æ¯è‚¡å‡€èµ„äº§': '',
            'å‡€èµ„äº§æ”¶ç›Šç‡': '',
            'æ€»èµ„äº§æ”¶ç›Šç‡': '',
            'æ¯›åˆ©ç‡': '',
            'å‡€åˆ©ç‡': '',
            'è¥ä¸šåˆ©æ¶¦ç‡': '',
            
            # ä¼°å€¼æŒ‡æ ‡
            'å¸‚ç›ˆç‡ï¼ˆé™ï¼‰': '',
            'å¸‚ç›ˆç‡ï¼ˆTTMï¼‰': '',
            'å¸‚å‡€ç‡': '',
            'å¸‚é”€ç‡': '',
            'è‚¡æ¯ç‡': '',
            
            # æˆé•¿æ€§
            'è¥ä¸šæ”¶å…¥å¢é•¿ç‡': '',
            'å‡€åˆ©æ¶¦å¢é•¿ç‡': '',
            'å‡€èµ„äº§å¢é•¿ç‡': '',
            'å‡€åˆ©æ¶¦å¢é€Ÿ': '',
            
            # å¿å€ºèƒ½åŠ›
            'èµ„äº§è´Ÿå€ºç‡': '',
            'æµåŠ¨æ¯”ç‡': '',
            'é€ŸåŠ¨æ¯”ç‡': '',
            
            # è¿è¥èƒ½åŠ›
            'æ€»èµ„äº§å‘¨è½¬ç‡': '',
            'å­˜è´§å‘¨è½¬ç‡': '',
            'åº”æ”¶è´¦æ¬¾å‘¨è½¬ç‡': '',
            
            # ç°é‡‘æµ
            'æ¯è‚¡ç»è¥ç°é‡‘æµ': '',
            'ç°é‡‘æµé‡æ¯”ç‡': ''
        }
        
        # è·å–æœ€æ–°å¹´ä»½å’Œå­£åº¦
        current_year = datetime.now().year
        current_quarter = (datetime.now().month - 1) // 3 + 1
        
        # å°è¯•è·å–æœ€è¿‘4ä¸ªå­£åº¦çš„æ•°æ®ï¼Œç›´åˆ°æˆåŠŸ
        for year_offset in range(0, 2):
            for quarter_offset in range(0, 4):
                year = current_year - year_offset
                if year < 2007:  # baostockä»2007å¹´å¼€å§‹æä¾›æ•°æ®
                    break
                
                quarter = current_quarter - quarter_offset
                if quarter < 1:
                    quarter += 4
                    year -= 1
                
                # è·å–å­£é¢‘ç›ˆåˆ©èƒ½åŠ›æ•°æ®
                rs_profit = bs.query_profit_data(code=market_code, year=year, quarter=quarter)
                if rs_profit.error_code == '0':
                    profit_data = []
                    while rs_profit.error_code == '0' and rs_profit.next():
                        profit_data.append(rs_profit.get_row_data())
                    
                    if profit_data:
                        # æå–ç›ˆåˆ©èƒ½åŠ›æ•°æ®
                        data = profit_data[0]
                        if len(data) > 4:
                            fundamental['å‡€èµ„äº§æ”¶ç›Šç‡'] = str(data[4])  # roe
                        if len(data) > 5:
                            fundamental['å‡€åˆ©ç‡'] = str(data[5])  # net_profit_ratio
                        if len(data) > 6:
                            fundamental['è¥ä¸šåˆ©æ¶¦ç‡'] = str(data[6])  # operating_profit_ratio
                        if len(data) > 7:
                            fundamental['æ¯›åˆ©ç‡'] = str(data[7])  # gross_profit_ratio
                        if len(data) > 11:
                            fundamental['æ¯è‚¡æ”¶ç›Š'] = str(data[11])  # eps
                        if len(data) > 12:
                            fundamental['æ¯è‚¡å‡€èµ„äº§'] = str(data[12])  # bps
                        
                        # æ·»åŠ éšæœºå»¶è¿Ÿ
                        add_random_delay()
                        
                        # è·å–èµ„äº§è´Ÿå€ºè¡¨æ•°æ®
                        rs_balance = bs.query_balance_data(code=market_code, year=year, quarter=quarter)
                        if rs_balance.error_code == '0':
                            balance_data = []
                            while rs_balance.error_code == '0' and rs_balance.next():
                                balance_data.append(rs_balance.get_row_data())
                            
                            if balance_data:
                                data = balance_data[0]
                                if len(data) > 13:
                                    fundamental['èµ„äº§è´Ÿå€ºç‡'] = str(data[13])  # debt_to_assets_ratio
                                if len(data) > 14:
                                    current_ratio = float(data[14]) if data[14] else 0
                                    quick_ratio = float(data[15]) if data[15] else 0
                                    fundamental['æµåŠ¨æ¯”ç‡'] = str(current_ratio)
                                    fundamental['é€ŸåŠ¨æ¯”ç‡'] = str(quick_ratio)
                        
                        # æ·»åŠ éšæœºå»¶è¿Ÿ
                        add_random_delay()
                        
                        # è·å–ç°é‡‘æµé‡è¡¨æ•°æ®
                        rs_cash = bs.query_cash_flow_data(code=market_code, year=year, quarter=quarter)
                        if rs_cash.error_code == '0':
                            cash_data = []
                            while rs_cash.error_code == '0' and rs_cash.next():
                                cash_data.append(rs_cash.get_row_data())
                            
                            if cash_data:
                                data = cash_data[0]
                                if len(data) > 24:
                                    fundamental['æ¯è‚¡ç»è¥ç°é‡‘æµ'] = str(data[24])  # per_share_operation_cash_flow
                        
                        # è·å–å…¬å¸åŸºæœ¬ä¿¡æ¯
                        rs_stock_basic = bs.query_stock_basic(code=market_code)
                        if rs_stock_basic.error_code == '0':
                            basic_data = []
                            while rs_stock_basic.error_code == '0' and rs_stock_basic.next():
                                basic_data.append(rs_stock_basic.get_row_data())
                            
                            if basic_data:
                                data = basic_data[0]
                                fundamental['è‚¡ç¥¨åç§°'] = str(data[1]) if len(data) > 1 else ''
                                fundamental['è‚¡ç¥¨ä¸Šå¸‚æ—¥æœŸ'] = str(data[3]) if len(data) > 3 else ''
                                fundamental['è‚¡ç¥¨æ‰€å±è¡Œä¸š'] = str(data[7]) if len(data) > 7 else ''
                        
                        # è·å–ä¼°å€¼æ•°æ® - ä½¿ç”¨æ—¥Kçº¿æ•°æ®ä¸­çš„å¸‚ç›ˆç‡ç­‰ä¿¡æ¯
                        rs_kdata = bs.query_history_k_data_plus(market_code, 
                                                              "date,peTTM,pbMRQ,psTTM,pcfNcfTTM",
                                                              start_date=f"{year-1}-01-01", 
                                                              end_date=f"{year}-12-31", 
                                                              frequency="d", 
                                                              adjustflag="3")
                        
                        if rs_kdata.error_code == '0':
                            kdata_list = []
                            while rs_kdata.error_code == '0' and rs_kdata.next():
                                kdata_list.append(rs_kdata.get_row_data())
                            
                            if kdata_list:
                                # å–æœ€æ–°çš„ä¼°å€¼æ•°æ®
                                latest_kdata = kdata_list[-1]
                                fundamental['å¸‚ç›ˆç‡ï¼ˆTTMï¼‰'] = str(latest_kdata[1]) if len(latest_kdata) > 1 else ''
                                fundamental['å¸‚å‡€ç‡'] = str(latest_kdata[2]) if len(latest_kdata) > 2 else ''
                                fundamental['å¸‚é”€ç‡'] = str(latest_kdata[3]) if len(latest_kdata) > 3 else ''
                                fundamental['ç°é‡‘æµé‡æ¯”ç‡'] = str(latest_kdata[4]) if len(latest_kdata) > 4 else ''
                        
                        break  # æˆåŠŸè·å–æ•°æ®åè·³å‡ºå¾ªç¯
            if fundamental['è‚¡ç¥¨åç§°']:  # å¦‚æœå·²è·å–åˆ°è‚¡ç¥¨åç§°ï¼Œè¡¨ç¤ºæ•°æ®è·å–æˆåŠŸ
                break
        
        bs.logout()
        
        # æ£€æŸ¥æ•°æ®æ˜¯å¦å®Œæ•´
        if fundamental['è‚¡ç¥¨åç§°']:
            # è®¡ç®—ä¸€äº›æœªç›´æ¥è·å–çš„æŒ‡æ ‡
            if fundamental['å‡€åˆ©æ¶¦å¢é€Ÿ'] == '' and fundamental['å‡€åˆ©æ¶¦å¢é•¿ç‡'] != '':
                fundamental['å‡€åˆ©æ¶¦å¢é€Ÿ'] = fundamental['å‡€åˆ©æ¶¦å¢é•¿ç‡']
            
            logger.info(f"âœ… ä½¿ç”¨baostockè·å– {code} - {fundamental['è‚¡ç¥¨åç§°']} æ•°æ®æˆåŠŸ")
            return fundamental
        else:
            logger.warning(f"âš ï¸  {code} æ•°æ®ä¸å®Œæ•´")
            return None
            
    except Exception as e:
        logger.error(f"âŒ baostockè·å– {code} æ•°æ®å¤±è´¥: {str(e)}")
        if BAOSTOCK_AVAILABLE:
            try:
                bs.logout()
            except:
                pass
        return None

def save_batch_to_csv(batch_data, mode='a'):
    """å°†æ‰¹æ¬¡æ•°æ®ä¿å­˜åˆ°CSVæ–‡ä»¶"""
    try:
        df = pd.DataFrame(batch_data)
        
        # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
        numeric_columns = [
            'æ¯è‚¡æ”¶ç›Š', 'æ¯è‚¡å‡€èµ„äº§', 'å‡€èµ„äº§æ”¶ç›Šç‡', 'æ€»èµ„äº§æ”¶ç›Šç‡', 'æ¯›åˆ©ç‡', 'å‡€åˆ©ç‡', 'è¥ä¸šåˆ©æ¶¦ç‡',
            'å¸‚ç›ˆç‡ï¼ˆé™ï¼‰', 'å¸‚ç›ˆç‡ï¼ˆTTMï¼‰', 'å¸‚å‡€ç‡', 'å¸‚é”€ç‡', 'è‚¡æ¯ç‡',
            'è¥ä¸šæ”¶å…¥å¢é•¿ç‡', 'å‡€åˆ©æ¶¦å¢é•¿ç‡', 'å‡€èµ„äº§å¢é•¿ç‡', 'å‡€åˆ©æ¶¦å¢é€Ÿ',
            'èµ„äº§è´Ÿå€ºç‡', 'æµåŠ¨æ¯”ç‡', 'é€ŸåŠ¨æ¯”ç‡',
            'æ€»èµ„äº§å‘¨è½¬ç‡', 'å­˜è´§å‘¨è½¬ç‡', 'åº”æ”¶è´¦æ¬¾å‘¨è½¬ç‡',
            'æ¯è‚¡ç»è¥ç°é‡‘æµ', 'ç°é‡‘æµé‡æ¯”ç‡'
        ]
        
        for col in df.columns:
            if col in numeric_columns:
                df[col] = df[col].replace(['', 'None', 'nan'], np.nan)
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        if mode == 'w' or not os.path.exists('cache/stockA_fundamentals_baostock.csv'):
            df.to_csv('cache/stockA_fundamentals_baostock.csv', index=False, encoding='utf-8-sig')
        else:
            df.to_csv('cache/stockA_fundamentals_baostock.csv', index=False, encoding='utf-8-sig', mode='a', header=False)
        
        return True
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜æ‰¹æ¬¡æ•°æ®å¤±è´¥: {e}")
        return False

def update_log(stock_count):
    """æ›´æ–°æ—¥å¿—æ–‡ä»¶"""
    try:
        log_data = {
            "æ›´æ–°æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "è‚¡ç¥¨æ•°é‡": stock_count,
            "æ•°æ®æº": "baostock",
            "å¯ç”¨æ•°æ®æº": {
                "baostock": BAOSTOCK_AVAILABLE
            },
            "æ–‡ä»¶è·¯å¾„": "cache/stockA_fundamentals_baostock.csv",
            "åŒ…å«å­—æ®µ": [
                "è‚¡ç¥¨ä»£ç ", "è‚¡ç¥¨åç§°", "è‚¡ç¥¨ä¸Šå¸‚æ—¥æœŸ", "è‚¡ç¥¨ä¸Šå¸‚åœ°ç‚¹", "è‚¡ç¥¨æ‰€å±è¡Œä¸š",
                # ç›ˆåˆ©èƒ½åŠ›
                "æ¯è‚¡æ”¶ç›Š", "æ¯è‚¡å‡€èµ„äº§", "å‡€èµ„äº§æ”¶ç›Šç‡", "æ€»èµ„äº§æ”¶ç›Šç‡", "æ¯›åˆ©ç‡", "å‡€åˆ©ç‡", "è¥ä¸šåˆ©æ¶¦ç‡",
                # ä¼°å€¼æŒ‡æ ‡
                "å¸‚ç›ˆç‡ï¼ˆé™ï¼‰", "å¸‚ç›ˆç‡ï¼ˆTTMï¼‰", "å¸‚å‡€ç‡", "å¸‚é”€ç‡", "è‚¡æ¯ç‡",
                # æˆé•¿æ€§
                "è¥ä¸šæ”¶å…¥å¢é•¿ç‡", "å‡€åˆ©æ¶¦å¢é•¿ç‡", "å‡€èµ„äº§å¢é•¿ç‡", "å‡€åˆ©æ¶¦å¢é€Ÿ",
                # å¿å€ºèƒ½åŠ›
                "èµ„äº§è´Ÿå€ºç‡", "æµåŠ¨æ¯”ç‡", "é€ŸåŠ¨æ¯”ç‡",
                # è¿è¥èƒ½åŠ›
                "æ€»èµ„äº§å‘¨è½¬ç‡", "å­˜è´§å‘¨è½¬ç‡", "åº”æ”¶è´¦æ¬¾å‘¨è½¬ç‡",
                # ç°é‡‘æµ
                "æ¯è‚¡ç»è¥ç°é‡‘æµ", "ç°é‡‘æµé‡æ¯”ç‡"
            ],
            "è´¢åŠ¡æŒ‡æ ‡ç»´åº¦": {
                "ç›ˆåˆ©èƒ½åŠ›": ["æ¯è‚¡æ”¶ç›Š", "æ¯è‚¡å‡€èµ„äº§", "å‡€èµ„äº§æ”¶ç›Šç‡", "æ¯›åˆ©ç‡", "å‡€åˆ©ç‡", "è¥ä¸šåˆ©æ¶¦ç‡"],
                "ä¼°å€¼æŒ‡æ ‡": ["å¸‚ç›ˆç‡ï¼ˆTTMï¼‰", "å¸‚å‡€ç‡", "å¸‚é”€ç‡"],
                "å¿å€ºèƒ½åŠ›": ["èµ„äº§è´Ÿå€ºç‡", "æµåŠ¨æ¯”ç‡", "é€ŸåŠ¨æ¯”ç‡"],
                "ç°é‡‘æµ": ["æ¯è‚¡ç»è¥ç°é‡‘æµ"]
            }
        }
        
        with open('cache/fundamentals_baostock_update_log.json', 'w', encoding='utf-8') as f:
            json.dump(log_data, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°æ—¥å¿—å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°ï¼šè·å–Aè‚¡è‚¡ç¥¨å®Œæ•´åŸºæœ¬é¢æ•°æ®ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ """
    logger.info("ğŸš€ å¼€å§‹è·å–Aè‚¡è‚¡ç¥¨baostockåŸºæœ¬é¢æ•°æ®...")
    logger.info("ğŸ“Š ä½¿ç”¨baostockæ•°æ®æºè·å–åŸºæœ¬é¢æ•°æ®")
    
    # æ˜¾ç¤ºå¯ç”¨æ•°æ®æºçŠ¶æ€
    logger.info("ğŸ“¡ æ•°æ®æºçŠ¶æ€:")
    logger.info(f"   baostock: {'âœ… å¯ç”¨' if BAOSTOCK_AVAILABLE else 'âŒ æœªå®‰è£…'}")
    
    if not BAOSTOCK_AVAILABLE:
        logger.error("âŒ baostockåº“æœªå®‰è£…ï¼Œæ— æ³•è·å–æ•°æ®ï¼Œè¯·è¿è¡Œ pip install baostock åé‡è¯•")
        return
    
    # è·å–è‚¡ç¥¨åˆ—è¡¨
    stock_list = get_stock_list()
    if stock_list is None:
        return
    
    stock_codes = stock_list['code'].astype(str).str.zfill(6).tolist()
    total_stocks = len(stock_codes)
    
    # åŠ è½½è¿›åº¦
    progress = load_progress()
    start_index = progress["last_index"]
    completed_codes = set(progress["completed_codes"])
    
    logger.info(f"ğŸ“Š å…±{total_stocks}åªè‚¡ç¥¨ï¼Œä»ç¬¬{start_index+1}åªå¼€å§‹è·å–...")
    logger.info(f"âœ… å·²å®Œæˆ{len(completed_codes)}åªè‚¡ç¥¨")
    
    if start_index >= total_stocks:
        logger.info("ğŸ‰ æ‰€æœ‰è‚¡ç¥¨æ•°æ®å·²è·å–å®Œæˆï¼")
        return
    
    # è·å–å¾…å¤„ç†çš„è‚¡ç¥¨
    remaining_codes = [code for code in stock_codes[start_index:] if code not in completed_codes]
    
    if not remaining_codes:
        logger.info("ğŸ‰ æ²¡æœ‰éœ€è¦è·å–çš„è‚¡ç¥¨æ•°æ®")
        return
    
    # åˆå§‹åŒ–æˆ–è¿½åŠ æ¨¡å¼
    mode = 'w' if start_index == 0 else 'a'
    
    # åˆ†æ‰¹è·å–æ•°æ®
    batch_size = 20  # æ¯æ‰¹å¤„ç†20åªè‚¡ç¥¨ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
    success_count = len(completed_codes)
    
    try:
        for i in range(0, len(remaining_codes), batch_size):
            batch_codes = remaining_codes[i:i+batch_size]
            batch_fundamentals = []
            
            current_start = start_index + i + 1
            current_end = min(start_index + i + batch_size, total_stocks)
            logger.info(f"\nğŸ”„ å¤„ç†ç¬¬{current_start}-{current_end}åªè‚¡ç¥¨...")
            
            # æ£€æŸ¥å½“å‰æ‰¹æ¬¡çš„æ€»ä½“è®¿é—®é¢‘ç‡
            if i > 0:  # ä¸æ˜¯ç¬¬ä¸€æ‰¹
                # æ ¹æ®é…ç½®æ·»åŠ æ‰¹æ¬¡é—´å»¶è¿Ÿ
                batch_delay = random.uniform(ANTI_CRAWL_CONFIG.BATCH_MIN_DELAY, ANTI_CRAWL_CONFIG.BATCH_MAX_DELAY)
                logger.info(f"   â±ï¸  æ‰¹æ¬¡é—´å»¶è¿Ÿ: {batch_delay:.2f}ç§’")
                time.sleep(batch_delay)
            
            for j, code in enumerate(batch_codes):
                # é‡è¯•æœºåˆ¶
                retry_count = 0
                while retry_count < AntiCrawlConfig.MAX_RETRIES:
                    fundamental = get_fundamentals_from_baostock(code)
                    if fundamental:
                        break
                    retry_count += 1
                    logger.warning(f"   ğŸ”„ é‡è¯•è·å– {code} æ•°æ® ({retry_count}/{AntiCrawlConfig.MAX_RETRIES})")
                    time.sleep(random.uniform(2, 5))  # é‡è¯•å‰å¢åŠ è¾ƒé•¿å»¶è¿Ÿ
                
                if fundamental and fundamental['è‚¡ç¥¨åç§°']:
                    batch_fundamentals.append(fundamental)
                    success_count += 1
                    completed_codes.add(code)
                else:
                    logger.warning(f"   âš ï¸  {code} æ•°æ®è·å–å¤±è´¥æˆ–ä¸å®Œæ•´ï¼Œè·³è¿‡")
                
                # é—´éš”æ—¶é—´é¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(ANTI_CRAWL_CONFIG.STOCK_MIN_INTERVAL)
            
            # ä¿å­˜æ‰¹æ¬¡æ•°æ®
            if batch_fundamentals:
                if save_batch_to_csv(batch_fundamentals, mode):
                    current_index = start_index + i + len(batch_codes)
                    save_progress(current_index, list(completed_codes))
                    logger.info(f"   ğŸ’¾ æ‰¹æ¬¡æ•°æ®å·²ä¿å­˜ ({len(batch_fundamentals)}æ¡è®°å½•)")
                    mode = 'a'  # åç»­æ‰¹æ¬¡ä½¿ç”¨è¿½åŠ æ¨¡å¼
            else:
                logger.warning(f"   âš ï¸  æœ¬æ‰¹æ¬¡æ— æœ‰æ•ˆæ•°æ®")
        
        # æ›´æ–°æœ€ç»ˆæ—¥å¿—
        update_log(success_count)
        
        logger.info(f"\nğŸ‰ æ•°æ®è·å–å®Œæˆï¼")
        logger.info(f"ğŸ“Š æˆåŠŸè·å– {success_count}/{total_stocks} åªè‚¡ç¥¨çš„çœŸå®æ•°æ®")
        logger.info(f"ğŸ“ æ•°æ®å·²ä¿å­˜åˆ° cache/stockA_fundamentals_baostock.csv")
        logger.info(f"ğŸ“¡ æ•°æ®æº: baostock")
        logger.info(f"ğŸ“ˆ æ•°æ®åŒ…å«å®Œæ•´è´¢åŠ¡æŒ‡æ ‡ï¼šç›ˆåˆ©èƒ½åŠ›ã€ä¼°å€¼ã€å¿å€ºèƒ½åŠ›ã€ç°é‡‘æµç­‰ç»´åº¦")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if os.path.exists('cache/stockA_fundamentals_baostock.csv'):
            df = pd.read_csv('cache/stockA_fundamentals_baostock.csv')
            logger.info(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡ï¼š")
            logger.info(f"   ğŸ“Š æ€»è®°å½•æ•°: {len(df)}")
            
            # æ˜¾ç¤ºæœ‰æ•ˆæ•°æ®ç»Ÿè®¡
            valid_data = df[df['è‚¡ç¥¨åç§°'].notna() & (df['è‚¡ç¥¨åç§°'] != '')]
            logger.info(f"   âœ… æœ‰æ•ˆæ•°æ®: {len(valid_data)}")
            
            if len(valid_data) > 0:
                # è¡Œä¸šåˆ†å¸ƒ
                industry_counts = valid_data['è‚¡ç¥¨æ‰€å±è¡Œä¸š'].value_counts()
                if len(industry_counts) > 0:
                    logger.info(f"   ğŸ¢ ä¸»è¦è¡Œä¸š: {industry_counts.head(3).to_dict()}")
                
                # æ˜¾ç¤ºå‰å‡ æ¡æ•°æ®
                logger.info(f"\nğŸ“‹ æ•°æ®é¢„è§ˆ:")
                preview_cols = ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'è‚¡ç¥¨æ‰€å±è¡Œä¸š', 'æ¯è‚¡æ”¶ç›Š', 'å‡€èµ„äº§æ”¶ç›Šç‡', 'å¸‚ç›ˆç‡ï¼ˆTTMï¼‰', 'å¸‚å‡€ç‡']
                available_cols = [col for col in preview_cols if col in valid_data.columns]
                logger.info(valid_data[available_cols].head().to_string())
        
    except KeyboardInterrupt:
        logger.warning(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œè¿›åº¦å·²ä¿å­˜")
        logger.warning(f"   å·²å®Œæˆ {success_count} åªè‚¡ç¥¨")
        save_progress(success_count, list(completed_codes))
        update_log(success_count)
    
    except Exception as e:
        logger.error(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
        logger.error(f"   å·²å®Œæˆ {success_count} åªè‚¡ç¥¨")
        save_progress(success_count, list(completed_codes))
        update_log(success_count)

if __name__ == "__main__":
    main()