#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Aè‚¡è‚¡ç¥¨åŸºæœ¬é¢æ•°æ®ç¼“å­˜ç³»ç»Ÿ
åŠŸèƒ½ï¼š
1. ç¼“å­˜æ‰€æœ‰Aè‚¡è‚¡ç¥¨çš„å®Œæ•´åŸºæœ¬é¢æ•°æ®
2. æ”¯æŒå®šæœŸæ›´æ–°æœºåˆ¶ï¼ˆé»˜è®¤ä¸€ä¸ªæœˆï¼‰
3. åŒ…å«README.mdè¦æ±‚çš„æ‰€æœ‰æ•°æ®å­—æ®µ
4. æ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œåˆ†æ‰¹å¤„ç†
"""

import os
import json
import pandas as pd
import numpy as np
import akshare as ak
from datetime import datetime, timedelta
import time
import warnings
warnings.filterwarnings('ignore')

class StockFundamentalsCache:
    """Aè‚¡è‚¡ç¥¨åŸºæœ¬é¢æ•°æ®ç¼“å­˜ç³»ç»Ÿ"""
    
    def __init__(self):
        self.cache_dir = 'cache'
        self.fundamentals_cache = os.path.join(self.cache_dir, 'stockA_fundamentals.csv')
        self.stock_list_cache = os.path.join(self.cache_dir, 'stockA_list.csv')
        self.update_log = os.path.join(self.cache_dir, 'update_log.json')
        
        # åˆ›å»ºç¼“å­˜ç›®å½•
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)
            
        # å®šä¹‰å®Œæ•´çš„æ•°æ®å­—æ®µ
        self.required_fields = {
            # åŸºæœ¬ä¿¡æ¯
            'code': 'è‚¡ç¥¨ä»£ç ',
            'name': 'è‚¡ç¥¨åç§°', 
            'list_date': 'ä¸Šå¸‚æ—¥æœŸ',
            'exchange': 'äº¤æ˜“æ‰€',
            'industry': 'æ‰€å±è¡Œä¸š',
            'sector': 'æ‰€å±åœ°åŒº',
            'company_name': 'å…¬å¸åç§°',
            'company_industry': 'å…¬å¸è¡Œä¸š',
            'company_region': 'å…¬å¸åœ°åŒº',
            'ceo': 'æ€»ç»ç†',
            'chairman': 'è‘£äº‹é•¿',
            'secretary': 'è‘£ç§˜',
            'employees': 'å‘˜å·¥äººæ•°',
            
            # è´¢åŠ¡æ•°æ®
            'total_assets': 'æ€»èµ„äº§(ä¸‡)',
            'total_liabilities': 'æ€»è´Ÿå€º(ä¸‡)',
            'total_equity': 'è‚¡ä¸œæƒç›Š(ä¸‡)',
            'revenue': 'è¥ä¸šæ”¶å…¥(ä¸‡)',
            'net_profit': 'å‡€åˆ©æ¶¦(ä¸‡)',
            'operating_cash_flow': 'ç»è¥ç°é‡‘æµ(ä¸‡)',
            'eps': 'æ¯è‚¡æ”¶ç›Š(å…ƒ)',
            'pe_static': 'å¸‚ç›ˆç‡(é™)',
            'pe_ttm': 'å¸‚ç›ˆç‡(TTM)',
            'gross_margin': 'æ¯›åˆ©ç‡(%)',
            'net_margin': 'å‡€åˆ©ç‡(%)',
            'roe': 'å‡€èµ„äº§æ”¶ç›Šç‡(%)',
            'debt_ratio': 'èµ„äº§è´Ÿå€ºç‡(%)',
            'revenue_growth': 'è¥æ”¶å¢é•¿ç‡(%)',
            'profit_growth': 'å‡€åˆ©æ¶¦å¢é•¿ç‡(%)',
            
            # å¸‚åœºæ•°æ®
            'current_price': 'å½“å‰ä»·æ ¼',
            'market_cap': 'æ€»å¸‚å€¼(äº¿)',
            'pb': 'å¸‚å‡€ç‡',
            'dividend_yield': 'è‚¡æ¯ç‡(%)',
            
            # æ›´æ–°æ—¶é—´
            'update_time': 'æ›´æ–°æ—¶é—´'
        }

    def should_update_cache(self, days=30):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ç¼“å­˜"""
        if not os.path.exists(self.fundamentals_cache):
            return True
            
        # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
        file_time = datetime.fromtimestamp(os.path.getmtime(self.fundamentals_cache))
        if datetime.now() - file_time >= timedelta(days=days):
            return True
            
        # æ£€æŸ¥æ›´æ–°æ—¥å¿—
        if os.path.exists(self.update_log):
            try:
                with open(self.update_log, 'r', encoding='utf-8') as f:
                    log_data = json.load(f)
                    last_update = datetime.fromisoformat(log_data['last_update'])
                    if datetime.now() - last_update >= timedelta(days=days):
                        return True
            except:
                pass
                
        return False

    def get_stock_list(self):
        """è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨"""
        if os.path.exists(self.stock_list_cache):
            print("ğŸ“‚ ä»ç¼“å­˜åŠ è½½Aè‚¡è‚¡ç¥¨åˆ—è¡¨...")
            try:
                return pd.read_csv(self.stock_list_cache)
            except:
                pass
                
        print("ğŸ”„ ä»ç½‘ç»œè·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨...")
        try:
            # è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨
            stock_list = ak.stock_zh_a_spot_em()
            stock_data = stock_list[['ä»£ç ', 'åç§°']].rename(columns={'ä»£ç ': 'code', 'åç§°': 'name'})
            
            # ä¿å­˜åˆ°ç¼“å­˜
            stock_data.to_csv(self.stock_list_cache, index=False, encoding='utf-8')
            print(f"âœ… Aè‚¡è‚¡ç¥¨åˆ—è¡¨å·²ç¼“å­˜ï¼Œå…±{len(stock_data)}åªè‚¡ç¥¨")
            return stock_data
            
        except Exception as e:
            print(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_company_info(self, code):
        """è·å–å…¬å¸åŸºæœ¬ä¿¡æ¯"""
        try:
            # è·å–å…¬å¸åŸºæœ¬ä¿¡æ¯
            company_info = ak.stock_individual_info_em(symbol=code)
            
            # è·å–å…¬å¸é«˜ç®¡ä¿¡æ¯
            try:
                manager_info = ak.stock_individual_executive_em(symbol=code)
                ceo = manager_info[manager_info['èŒä½'] == 'æ€»ç»ç†']['å§“å'].iloc[0] if len(manager_info) > 0 else ''
                chairman = manager_info[manager_info['èŒä½'] == 'è‘£äº‹é•¿']['å§“å'].iloc[0] if len(manager_info) > 0 else ''
                secretary = manager_info[manager_info['èŒä½'] == 'è‘£ç§˜']['å§“å'].iloc[0] if len(manager_info) > 0 else ''
            except:
                ceo = chairman = secretary = ''
            
            return {
                'list_date': company_info[company_info['item'] == 'ä¸Šå¸‚æ—¶é—´']['value'].iloc[0] if len(company_info) > 0 else '',
                'exchange': company_info[company_info['item'] == 'å¸‚åœº']['value'].iloc[0] if len(company_info) > 0 else '',
                'industry': company_info[company_info['item'] == 'è¡Œä¸š']['value'].iloc[0] if len(company_info) > 0 else '',
                'employees': company_info[company_info['item'] == 'å‘˜å·¥äººæ•°']['value'].iloc[0] if len(company_info) > 0 else '',
                'ceo': ceo,
                'chairman': chairman,
                'secretary': secretary
            }
        except:
            return {}

    def get_financial_data(self, code):
        """è·å–è´¢åŠ¡æ•°æ®"""
        try:
            # è·å–æœ€æ–°è´¢åŠ¡æ•°æ®
            financial_data = {}
            
            # è·å–è´¢åŠ¡æ‘˜è¦
            try:
                abstract = ak.stock_financial_abstract_ths(symbol=code)
                if not abstract.empty:
                    latest = abstract.iloc[0]
                    financial_data.update({
                        'total_assets': latest.get('èµ„äº§æ€»è®¡', 0),
                        'total_liabilities': latest.get('è´Ÿå€ºåˆè®¡', 0),
                        'total_equity': latest.get('è‚¡ä¸œæƒç›Šåˆè®¡', 0),
                        'revenue': latest.get('è¥ä¸šæ”¶å…¥', 0),
                        'net_profit': latest.get('å‡€åˆ©æ¶¦', 0),
                        'operating_cash_flow': latest.get('ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢', 0)
                    })
            except:
                pass

            # è·å–è´¢åŠ¡æŒ‡æ ‡
            try:
                indicators = ak.stock_financial_analysis_indicator(symbol=code, indicator="å¹´åº¦")
                if not indicators.empty:
                    latest = indicators.iloc[0]
                    financial_data.update({
                        'eps': latest.get('æ¯è‚¡æ”¶ç›Š', 0),
                        'roe': latest.get('å‡€èµ„äº§æ”¶ç›Šç‡', 0),
                        'debt_ratio': latest.get('èµ„äº§è´Ÿå€ºæ¯”ç‡', 0),
                        'gross_margin': latest.get('é”€å”®æ¯›åˆ©ç‡', 0),
                        'net_margin': latest.get('é”€å”®å‡€åˆ©ç‡', 0)
                    })
            except:
                pass

            return financial_data
        except:
            return {}

    def get_market_data(self, code):
        """è·å–å¸‚åœºæ•°æ®"""
        try:
            # è·å–å®æ—¶è¡Œæƒ…
            spot_data = ak.stock_zh_a_spot_em()
            stock_data = spot_data[spot_data['ä»£ç '] == code]
            
            if not stock_data.empty:
                return {
                    'current_price': stock_data.iloc[0]['æœ€æ–°ä»·'],
                    'market_cap': stock_data.iloc[0]['æ€»å¸‚å€¼'] / 10000,  # è½¬æ¢ä¸ºäº¿
                    'pe_ttm': stock_data.iloc[0]['å¸‚ç›ˆç‡-åŠ¨æ€'],
                    'pb': stock_data.iloc[0]['å¸‚å‡€ç‡']
                }
        except:
            pass
            
        return {}

    def update_fundamentals_cache(self, batch_size=50, max_stocks=0):
        """æ›´æ–°åŸºæœ¬é¢æ•°æ®ç¼“å­˜"""
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stock_list = self.get_stock_list()
        if stock_list.empty:
            print("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
            return

        # è®¾ç½®å¤„ç†æ•°é‡
        total_stocks = len(stock_list)
        if max_stocks > 0:
            total_stocks = min(max_stocks, total_stocks)
            stock_list = stock_list.head(total_stocks)

        print(f"ğŸ“Š å¼€å§‹æ›´æ–°åŸºæœ¬é¢æ•°æ®ï¼Œå…±{total_stocks}åªè‚¡ç¥¨...")

        # æ–­ç‚¹ç»­ä¼ 
        checkpoint_file = os.path.join(self.cache_dir, 'fundamentals_update_checkpoint.json')
        processed_codes = set()
        
        if os.path.exists(checkpoint_file):
            try:
                with open(checkpoint_file, 'r', encoding='utf-8') as f:
                    checkpoint_data = json.load(f)
                    processed_codes = set(checkpoint_data.get('processed_codes', []))
                    print(f"ğŸ“‚ ä»æ–­ç‚¹ç»­ä¼ ï¼Œå·²å¤„ç†{len(processed_codes)}åªè‚¡ç¥¨")
            except:
                pass

        # åˆ†æ‰¹å¤„ç†
        fundamentals_data = []
        total_batches = (total_stocks + batch_size - 1) // batch_size
        
        for batch_idx in range(total_batches):
            start_idx = batch_idx * batch_size
            end_idx = min((batch_idx + 1) * batch_size, total_stocks)
            batch_stocks = stock_list.iloc[start_idx:end_idx]
            
            print(f"ğŸ”„ å¤„ç†ç¬¬{batch_idx+1}/{total_batches}æ‰¹ ({start_idx+1}-{end_idx}åªè‚¡ç¥¨)")
            
            for _, stock in batch_stocks.iterrows():
                code = str(stock['code']).zfill(6)
                name = str(stock['name'])
                
                if code in processed_codes:
                    continue
                
                try:
                    # æ”¶é›†æ‰€æœ‰æ•°æ®
                    stock_data = {'code': code, 'name': name}
                    
                    # å…¬å¸ä¿¡æ¯
                    company_info = self.get_company_info(code)
                    stock_data.update(company_info)
                    
                    # è´¢åŠ¡æ•°æ®
                    financial_data = self.get_financial_data(code)
                    stock_data.update(financial_data)
                    
                    # å¸‚åœºæ•°æ®
                    market_data = self.get_market_data(code)
                    stock_data.update(market_data)
                    
                    # æ›´æ–°æ—¶é—´
                    stock_data['update_time'] = datetime.now().isoformat()
                    
                    fundamentals_data.append(stock_data)
                    processed_codes.add(code)
                    
                    # å®æ—¶ä¿å­˜è¿›åº¦
                    if len(processed_codes) % batch_size == 0:
                        self._save_checkpoint(processed_codes, checkpoint_file)
                        print(f"ğŸ’¾ å·²å¤„ç†{len(processed_codes)}åªè‚¡ç¥¨ï¼Œè¿›åº¦å·²ä¿å­˜")
                        
                except Exception as e:
                    print(f"âš ï¸ å¤„ç†è‚¡ç¥¨{code}å¤±è´¥: {e}")
                    continue
            
            # æ¯æ‰¹å®Œæˆåä¿å­˜è¿›åº¦
            self._save_checkpoint(processed_codes, checkpoint_file)
            
            # é¿å…APIé™åˆ¶
            if batch_idx < total_batches - 1:
                time.sleep(1)

        # æ¸…ç†æ–­ç‚¹æ–‡ä»¶
        if os.path.exists(checkpoint_file):
            os.remove(checkpoint_file)

        # ä¿å­˜å®Œæ•´æ•°æ®
        if fundamentals_data:
            df = pd.DataFrame(fundamentals_data)
            
            # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨
            for field in self.required_fields.keys():
                if field not in df.columns:
                    df[field] = None
            
            # æŒ‰å­—æ®µé¡ºåºä¿å­˜
            df = df[list(self.required_fields.keys())]
            df.to_csv(self.fundamentals_cache, index=False, encoding='utf-8')
            
            # æ›´æ–°æ—¥å¿—
            update_info = {
                'last_update': datetime.now().isoformat(),
                'total_stocks': len(fundamentals_data),
                'cache_file': self.fundamentals_cache
            }
            
            with open(self.update_log, 'w', encoding='utf-8') as f:
                json.dump(update_info, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… åŸºæœ¬é¢æ•°æ®ç¼“å­˜æ›´æ–°å®Œæˆï¼Œå…±{len(fundamentals_data)}åªè‚¡ç¥¨")
            print(f"ğŸ“Š æ•°æ®å·²ä¿å­˜åˆ°: {self.fundamentals_cache}")
            
            return df
        else:
            print("âŒ æœªèƒ½è·å–æœ‰æ•ˆæ•°æ®")
            return pd.DataFrame()

    def _save_checkpoint(self, processed_codes, checkpoint_file):
        """ä¿å­˜å¤„ç†è¿›åº¦"""
        try:
            with open(checkpoint_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'processed_codes': list(processed_codes),
                    'timestamp': datetime.now().isoformat(),
                    'count': len(processed_codes)
                }, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ–­ç‚¹å¤±è´¥: {e}")

    def load_fundamentals_cache(self):
        """åŠ è½½åŸºæœ¬é¢æ•°æ®ç¼“å­˜"""
        if not os.path.exists(self.fundamentals_cache):
            print("âŒ åŸºæœ¬é¢æ•°æ®ç¼“å­˜ä¸å­˜åœ¨")
            return pd.DataFrame()
            
        try:
            df = pd.read_csv(self.fundamentals_cache)
            print(f"ğŸ“‚ å·²åŠ è½½åŸºæœ¬é¢æ•°æ®ç¼“å­˜ï¼Œå…±{len(df)}åªè‚¡ç¥¨")
            return df
        except Exception as e:
            print(f"âŒ åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_cache_info(self):
        """è·å–ç¼“å­˜ä¿¡æ¯"""
        info = {
            'fundamentals_exists': os.path.exists(self.fundamentals_cache),
            'stock_list_exists': os.path.exists(self.stock_list_cache),
            'update_log_exists': os.path.exists(self.update_log),
            'total_fields': len(self.required_fields)
        }
        
        if os.path.exists(self.fundamentals_cache):
            info['fundamentals_size'] = os.path.getsize(self.fundamentals_cache)
            info['fundamentals_modified'] = datetime.fromtimestamp(
                os.path.getmtime(self.fundamentals_cache)).isoformat()
                
        if os.path.exists(self.update_log):
            try:
                with open(self.update_log, 'r', encoding='utf-8') as f:
                    log_data = json.load(f)
                    info.update(log_data)
            except:
                pass
                
        return info

def main():
    """ä¸»å‡½æ•°"""
    cache = StockFundamentalsCache()
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
    if cache.should_update_cache(days=30):
        print("ğŸ”„ éœ€è¦æ›´æ–°åŸºæœ¬é¢æ•°æ®ç¼“å­˜")
        
        # è·å–ç¼“å­˜ä¿¡æ¯
        info = cache.get_cache_info()
        print(f"ğŸ“Š å½“å‰ç¼“å­˜ä¿¡æ¯: {json.dumps(info, indent=2, ensure_ascii=False)}")
        
        # æ›´æ–°ç¼“å­˜
        df = cache.update_fundamentals_cache(
            batch_size=int(os.getenv('BATCH_SIZE', 50)),
            max_stocks=int(os.getenv('MAX_STOCKS', 0))
        )
        
        if not df.empty:
            print(f"âœ… æ›´æ–°å®Œæˆï¼Œå…±{len(df)}åªè‚¡ç¥¨")
            print("ğŸ“Š æ•°æ®é¢„è§ˆ:")
            print(df.head())
    else:
        print("âœ… ç¼“å­˜æ•°æ®åœ¨æœ‰æ•ˆæœŸå†…ï¼Œæ— éœ€æ›´æ–°")
        
        # åŠ è½½ç°æœ‰ç¼“å­˜
        df = cache.load_fundamentals_cache()
        if not df.empty:
            print("ğŸ“Š ç¼“å­˜æ•°æ®æ¦‚è§ˆ:")
            print(f"- æ€»è‚¡ç¥¨æ•°: {len(df)}")
            print(f"- æ•°æ®å­—æ®µ: {len(df.columns)}")
            print(f"- æœ€åæ›´æ–°: {df['update_time'].max() if 'update_time' in df.columns else 'æœªçŸ¥'}")

if __name__ == "__main__":
    main()