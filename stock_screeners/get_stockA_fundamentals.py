import pandas as pd
import numpy as np
import time
import json
import os
import requests
from datetime import datetime
import warnings
import akshare as ak
warnings.filterwarnings('ignore')

def get_stock_list():
    """ä»æœ¬åœ°æ–‡ä»¶è¯»å–è‚¡ç¥¨åˆ—è¡¨"""
    try:
        stock_list = pd.read_csv('cache/stockA_list.csv')
        print(f"âœ… æˆåŠŸè¯»å–è‚¡ç¥¨åˆ—è¡¨ï¼Œå…±{len(stock_list)}åªè‚¡ç¥¨")
        return stock_list
    except Exception as e:
        print(f"âŒ è¯»å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        return None

def load_progress():
    """åŠ è½½è¿›åº¦ä¿¡æ¯"""
    progress_file = 'cache/fundamentals_progress.json'
    if os.path.exists(progress_file):
        try:
            with open(progress_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return {"last_index": 0, "completed_codes": []}

def save_progress(index, completed_codes):
    """ä¿å­˜è¿›åº¦ä¿¡æ¯"""
    progress_file = 'cache/fundamentals_progress.json'
    try:
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump({"last_index": index, "completed_codes": completed_codes}, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸  ä¿å­˜è¿›åº¦å¤±è´¥: {e}")

def get_fundamentals_real_data(code):
    """è·å–å•åªè‚¡ç¥¨çš„çœŸå®åŸºæœ¬é¢æ•°æ®"""
    try:
        # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        stock_info = ak.stock_individual_info_em(symbol=code)
        
        # è·å–æœ€æ–°è´¢åŠ¡æ•°æ®ï¼ˆä½¿ç”¨å¹´åº¦æ•°æ®ï¼‰
        try:
            # è·å–è´¢åŠ¡æŠ¥è¡¨æ‘˜è¦
            financial = ak.stock_financial_abstract_ths(symbol=code)
            if not financial.empty:
                # è·å–æœ€æ–°å¹´åº¦æ•°æ®
                annual_data = financial[financial['æŠ¥å‘ŠæœŸ'].str.contains('12-31')].iloc[0] if len(financial[financial['æŠ¥å‘ŠæœŸ'].str.contains('12-31')]) > 0 else financial.iloc[0]
            else:
                annual_data = pd.Series()
        except:
            annual_data = pd.Series()
        
        # è·å–å®æ—¶è¡Œæƒ…æ•°æ®
        try:
            # ä½¿ç”¨æ–°æµªå®æ—¶è¡Œæƒ…
            quote = ak.stock_zh_a_spot()
            quote_data = quote[quote['ä»£ç '] == code]
            if not quote_data.empty:
                current_price = quote_data.iloc[0]['æœ€æ–°ä»·']
                pe_ttm = quote_data.iloc[0]['å¸‚ç›ˆç‡TTM']
                pe_static = quote_data.iloc[0]['å¸‚ç›ˆç‡']
            else:
                current_price = None
                pe_ttm = None
                pe_static = None
        except:
            current_price = None
            pe_ttm = None
            pe_static = None
        
        # è·å–è‚¡ç¥¨æ¦‚å¿µå’Œè¡Œä¸šä¿¡æ¯
        try:
            concept = ak.stock_board_concept_cons_ths(symbol=code)
            industry = concept.iloc[0]['è¡Œä¸š'] if not concept.empty else ''
        except:
            industry = stock_info.get('è¡Œä¸š', '')
        
        # æ„å»ºåŸºæœ¬é¢æ•°æ®
        fundamental = {
            'è‚¡ç¥¨ä»£ç ': code,
            'è‚¡ç¥¨åç§°': str(stock_info.get('è‚¡ç¥¨ç®€ç§°', '')).strip(),
            'è‚¡ç¥¨ä¸Šå¸‚æ—¥æœŸ': '',  # éœ€è¦å•ç‹¬è·å–ä¸Šå¸‚æ—¥æœŸ
            'è‚¡ç¥¨ä¸Šå¸‚åœ°ç‚¹': 'ä¸Šæµ·' if str(code).startswith(('6', '5')) else 'æ·±åœ³',
            'è‚¡ç¥¨æ‰€å±è¡Œä¸š': str(industry).strip(),
            'æ¯è‚¡æ”¶ç›Š': str(annual_data.get('æ¯è‚¡æ”¶ç›Š', '')).strip() if pd.notna(annual_data.get('æ¯è‚¡æ”¶ç›Š', '')) else '',
            'å¸‚ç›ˆç‡ï¼ˆé™ï¼‰': str(pe_static).strip() if pe_static and str(pe_static) != 'nan' else '',
            'å¸‚ç›ˆç‡ï¼ˆTTMï¼‰': str(pe_ttm).strip() if pe_ttm and str(pe_ttm) != 'nan' else '',
            'æ¯›åˆ©ç‡': str(annual_data.get('æ¯›åˆ©ç‡', '')).strip() if pd.notna(annual_data.get('æ¯›åˆ©ç‡', '')) else '',
            'å‡€åˆ©ç‡': str(annual_data.get('å‡€åˆ©ç‡', '')).strip() if pd.notna(annual_data.get('å‡€åˆ©ç‡', '')) else '',
            'èµ„äº§æ”¶ç›Šç‡': str(annual_data.get('å‡€èµ„äº§æ”¶ç›Šç‡', '')).strip() if pd.notna(annual_data.get('å‡€èµ„äº§æ”¶ç›Šç‡', '')) else '',
            'èµ„äº§è´Ÿå€ºç‡': str(annual_data.get('èµ„äº§è´Ÿå€ºç‡', '')).strip() if pd.notna(annual_data.get('èµ„äº§è´Ÿå€ºç‡', '')) else '',
            'å‡€åˆ©æ¶¦å¢é€Ÿ': str(annual_data.get('å‡€åˆ©æ¶¦å¢é•¿ç‡', '')).strip() if pd.notna(annual_data.get('å‡€åˆ©æ¶¦å¢é•¿ç‡', '')) else ''
        }
        
        return fundamental
        
    except Exception as e:
        print(f"âŒ è·å– {code} æ•°æ®å¤±è´¥: {str(e)}")
        return {
            'è‚¡ç¥¨ä»£ç ': code,
            'è‚¡ç¥¨åç§°': '',
            'è‚¡ç¥¨ä¸Šå¸‚æ—¥æœŸ': '',
            'è‚¡ç¥¨ä¸Šå¸‚åœ°ç‚¹': 'ä¸Šæµ·' if str(code).startswith(('6', '5')) else 'æ·±åœ³',
            'è‚¡ç¥¨æ‰€å±è¡Œä¸š': '',
            'æ¯è‚¡æ”¶ç›Š': '',
            'å¸‚ç›ˆç‡ï¼ˆé™ï¼‰': '',
            'å¸‚ç›ˆç‡ï¼ˆTTMï¼‰': '',
            'æ¯›åˆ©ç‡': '',
            'å‡€åˆ©ç‡': '',
            'èµ„äº§æ”¶ç›Šç‡': '',
            'èµ„äº§è´Ÿå€ºç‡': '',
            'å‡€åˆ©æ¶¦å¢é€Ÿ': ''
        }

def save_batch_to_csv(batch_data, mode='a'):
    """å°†æ‰¹æ¬¡æ•°æ®ä¿å­˜åˆ°CSVæ–‡ä»¶"""
    try:
        df = pd.DataFrame(batch_data)
        
        # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
        for col in df.columns:
            if col in ['æ¯è‚¡æ”¶ç›Š', 'å¸‚ç›ˆç‡ï¼ˆé™ï¼‰', 'å¸‚ç›ˆç‡ï¼ˆTTMï¼‰', 'æ¯›åˆ©ç‡', 'å‡€åˆ©ç‡', 'èµ„äº§æ”¶ç›Šç‡', 'èµ„äº§è´Ÿå€ºç‡', 'å‡€åˆ©æ¶¦å¢é€Ÿ']:
                df[col] = df[col].replace('', np.nan)
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        if mode == 'w' or not os.path.exists('cache/stockA_fundamentals.csv'):
            df.to_csv('cache/stockA_fundamentals.csv', index=False, encoding='utf-8-sig')
        else:
            df.to_csv('cache/stockA_fundamentals.csv', index=False, encoding='utf-8-sig', mode='a', header=False)
        
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜æ‰¹æ¬¡æ•°æ®å¤±è´¥: {e}")
        return False

def update_log(stock_count, data_source):
    """æ›´æ–°æ—¥å¿—æ–‡ä»¶"""
    try:
        log_data = {
            "æ›´æ–°æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "è‚¡ç¥¨æ•°é‡": stock_count,
            "æ•°æ®æº": data_source,
            "æ–‡ä»¶è·¯å¾„": "cache/stockA_fundamentals.csv",
            "åŒ…å«å­—æ®µ": [
                "è‚¡ç¥¨ä»£ç ", "è‚¡ç¥¨åç§°", "è‚¡ç¥¨ä¸Šå¸‚æ—¥æœŸ", "è‚¡ç¥¨ä¸Šå¸‚åœ°ç‚¹", 
                "è‚¡ç¥¨æ‰€å±è¡Œä¸š", "æ¯è‚¡æ”¶ç›Š", "å¸‚ç›ˆç‡ï¼ˆé™ï¼‰", "å¸‚ç›ˆç‡ï¼ˆTTMï¼‰",
                "æ¯›åˆ©ç‡", "å‡€åˆ©ç‡", "èµ„äº§æ”¶ç›Šç‡", "èµ„äº§è´Ÿå€ºç‡", "å‡€åˆ©æ¶¦å¢é€Ÿ"
            ]
        }
        
        with open('cache/fundamentals_update_log.json', 'w', encoding='utf-8') as f:
            json.dump(log_data, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        print(f"âŒ æ›´æ–°æ—¥å¿—å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°ï¼šæ”¯æŒæ–­ç‚¹ç»­ä¼ çš„åˆ†æ‰¹è·å–"""
    print("ğŸš€ å¼€å§‹è·å–Aè‚¡è‚¡ç¥¨çœŸå®åŸºæœ¬é¢æ•°æ®...")
    
    # è·å–è‚¡ç¥¨åˆ—è¡¨
    stock_list = get_stock_list()
    if stock_list is None:
        return
    
    stock_codes = stock_list['code'].astype(str).str.zfill(6).tolist()
    total_stocks = len(stock_codes)
    
    # åŠ è½½è¿›åº¦
    progress = load_progress()
    start_index = progress["last_index"]
    completed_codes = set(progress["completed_codes"])
    
    print(f"ğŸ“Š å…±{total_stocks}åªè‚¡ç¥¨ï¼Œä»ç¬¬{start_index+1}åªå¼€å§‹è·å–...")
    print(f"âœ… å·²å®Œæˆ{len(completed_codes)}åªè‚¡ç¥¨")
    
    if start_index >= total_stocks:
        print("ğŸ‰ æ‰€æœ‰è‚¡ç¥¨æ•°æ®å·²è·å–å®Œæˆï¼")
        return
    
    # è·å–å¾…å¤„ç†çš„è‚¡ç¥¨
    remaining_codes = [code for code in stock_codes[start_index:] if code not in completed_codes]
    
    if not remaining_codes:
        print("ğŸ‰ æ²¡æœ‰éœ€è¦è·å–çš„è‚¡ç¥¨æ•°æ®")
        return
    
    # åˆå§‹åŒ–æˆ–è¿½åŠ æ¨¡å¼
    mode = 'w' if start_index == 0 else 'a'
    
    # åˆ†æ‰¹è·å–æ•°æ®
    batch_size = 20  # æ¯æ‰¹å¤„ç†20åªè‚¡ç¥¨ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
    success_count = len(completed_codes)
    
    try:
        for i in range(0, len(remaining_codes), batch_size):
            batch_codes = remaining_codes[i:i+batch_size]
            batch_fundamentals = []
            
            current_start = start_index + i + 1
            current_end = min(start_index + i + batch_size, total_stocks)
            print(f"\nğŸ”„ å¤„ç†ç¬¬{current_start}-{current_end}åªè‚¡ç¥¨...")
            
            for j, code in enumerate(batch_codes):
                fundamental = get_fundamentals_real_data(code)
                
                if fundamental['è‚¡ç¥¨åç§°'] and fundamental['è‚¡ç¥¨åç§°'] != '':
                    batch_fundamentals.append(fundamental)
                    success_count += 1
                    completed_codes.add(code)
                    
                    # æ¯åªè‚¡ç¥¨æ˜¾ç¤ºè¿›åº¦
                    print(f"   âœ… {code} - {fundamental['è‚¡ç¥¨åç§°']} å·²è·å–")
                else:
                    print(f"   âš ï¸  {code} æ•°æ®ä¸å®Œæ•´ï¼Œè·³è¿‡")
                
                # é—´éš”æ—¶é—´é¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(0.5)
            
            # ä¿å­˜æ‰¹æ¬¡æ•°æ®
            if batch_fundamentals:
                if save_batch_to_csv(batch_fundamentals, mode):
                    current_index = start_index + i + len(batch_codes)
                    save_progress(current_index, list(completed_codes))
                    print(f"   ğŸ’¾ æ‰¹æ¬¡æ•°æ®å·²ä¿å­˜ ({len(batch_fundamentals)}æ¡è®°å½•)")
                    mode = 'a'  # åç»­æ‰¹æ¬¡ä½¿ç”¨è¿½åŠ æ¨¡å¼
                
                # æ‰¹æ¬¡é—´éš”
                time.sleep(3)
            else:
                print(f"   âš ï¸  æœ¬æ‰¹æ¬¡æ— æœ‰æ•ˆæ•°æ®")
        
        # æ›´æ–°æœ€ç»ˆæ—¥å¿—
        update_log(success_count, "akshare_real_data")
        
        print(f"\nğŸ‰ æ•°æ®è·å–å®Œæˆï¼")
        print(f"ğŸ“Š æˆåŠŸè·å– {success_count}/{total_stocks} åªè‚¡ç¥¨çš„çœŸå®æ•°æ®")
        print(f"ğŸ“ æ•°æ®å·²ä¿å­˜åˆ° cache/stockA_fundamentals.csv")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if os.path.exists('cache/stockA_fundamentals.csv'):
            df = pd.read_csv('cache/stockA_fundamentals.csv')
            print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡ï¼š")
            print(f"   ğŸ“Š æ€»è®°å½•æ•°: {len(df)}")
            
            # æ˜¾ç¤ºæœ‰æ•ˆæ•°æ®ç»Ÿè®¡
            valid_data = df[df['è‚¡ç¥¨åç§°'].notna() & (df['è‚¡ç¥¨åç§°'] != '')]
            print(f"   âœ… æœ‰æ•ˆæ•°æ®: {len(valid_data)}")
            
            if len(valid_data) > 0:
                # è¡Œä¸šåˆ†å¸ƒ
                industry_counts = valid_data['è‚¡ç¥¨æ‰€å±è¡Œä¸š'].value_counts()
                if len(industry_counts) > 0:
                    print(f"   ğŸ¢ ä¸»è¦è¡Œä¸š: {industry_counts.head(3).to_dict()}")
                
                # æ˜¾ç¤ºå‰å‡ æ¡æ•°æ®
                print(f"\nğŸ“‹ æ•°æ®é¢„è§ˆ:")
                print(valid_data[['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'è‚¡ç¥¨æ‰€å±è¡Œä¸š', 'æ¯è‚¡æ”¶ç›Š', 'å¸‚ç›ˆç‡ï¼ˆé™ï¼‰']].head())
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œè¿›åº¦å·²ä¿å­˜")
        print(f"   å·²å®Œæˆ {success_count} åªè‚¡ç¥¨")
        save_progress(success_count, list(completed_codes))
        update_log(success_count, "akshare_real_data")
    
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
        print(f"   å·²å®Œæˆ {success_count} åªè‚¡ç¥¨")
        save_progress(success_count, list(completed_codes))
        update_log(success_count, "akshare_real_data")

if __name__ == "__main__":
    main()